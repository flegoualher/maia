{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36be80bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8aeec1",
   "metadata": {},
   "source": [
    "# 1. Import Images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6553954f",
   "metadata": {},
   "source": [
    "## 1.1 Convert tif to jpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "62fc5a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a folder with all jpeg images\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "TILE_RANGE = 1766\n",
    "\n",
    "IMAGE_INPUT_DIRECTORY = '/Users/user/Library/Mobile Documents/com~apple~CloudDocs/[02]-work/[02]-2023-le-wagon/[04]-final-project/train_data/train_lidar'\n",
    "IMAGE_OUTPUT_DIRECTORY = '/Users/user/Desktop/MAIA-yolo/0_second_run/train_lidar_tif'\n",
    "\n",
    "# Copying the images\n",
    "for i in range(TILE_RANGE):\n",
    "    input_image_path = os.path.join(IMAGE_INPUT_DIRECTORY, f'tile_{i}.tif')\n",
    "    output_image_path = os.path.join(IMAGE_OUTPUT_DIRECTORY, f'tile_{i}.tif')\n",
    "    shutil.copy2(input_image_path,output_image_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "5a03e01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Copy a given number of tiles to YOLO training folder\n",
    "\n",
    "tiles_number = 100\n",
    "val_percentage = 0.20\n",
    "\n",
    "IMAGE_INPUT_DIRECTORY = '/Users/user/Desktop/MAIA-yolo/0_second_run/train_lidar_jpeg/'\n",
    "IMAGE_OUTPUT_DIRECTORY_TRAIN = '/Users/user/Desktop/MAIA-yolo/0_second_run/datasets/images-v1/images/train/'\n",
    "IMAGE_OUTPUT_DIRECTORY_VAL = '/Users/user/Desktop/MAIA-yolo/0_second_run/datasets/images-v1/images/val/'\n",
    "\n",
    "#Copying the images\n",
    "for i in range(int(tiles_number*(1-val_percentage))):\n",
    "    input_image_path = os.path.join(IMAGE_INPUT_DIRECTORY, f'tile_{i}.jpeg')\n",
    "    output_image_path = os.path.join(IMAGE_OUTPUT_DIRECTORY_TRAIN, f'tile_{i}.jpeg')\n",
    "    shutil.copy2(input_image_path,output_image_path)\n",
    "    \n",
    "for i in range(int(tiles_number*(1-val_percentage)),int(tiles_number*(1-val_percentage) + tiles_number*val_percentage)):\n",
    "    input_image_path = os.path.join(IMAGE_INPUT_DIRECTORY, f'tile_{i}.jpeg')\n",
    "    output_image_path = os.path.join(IMAGE_OUTPUT_DIRECTORY_VAL, f'tile_{i}.jpeg')\n",
    "    shutil.copy2(input_image_path,output_image_path) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "06b2a399",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../../Maya_competition_lidar_data/images/train/tile_0_lidar.tif'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [15], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m input_image_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(IMAGE_INPUT_DIRECTORY, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtile_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_lidar.tif\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     16\u001b[0m output_image_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(IMAGE_OUTPUT_DIRECTORY, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtile_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.tif\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 17\u001b[0m \u001b[43mshutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy2\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_image_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43moutput_image_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/lib/python3.10/shutil.py:434\u001b[0m, in \u001b[0;36mcopy2\u001b[0;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[1;32m    432\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(dst):\n\u001b[1;32m    433\u001b[0m     dst \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(dst, os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(src))\n\u001b[0;32m--> 434\u001b[0m \u001b[43mcopyfile\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfollow_symlinks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_symlinks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    435\u001b[0m copystat(src, dst, follow_symlinks\u001b[38;5;241m=\u001b[39mfollow_symlinks)\n\u001b[1;32m    436\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dst\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/lib/python3.10/shutil.py:254\u001b[0m, in \u001b[0;36mcopyfile\u001b[0;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[1;32m    252\u001b[0m     os\u001b[38;5;241m.\u001b[39msymlink(os\u001b[38;5;241m.\u001b[39mreadlink(src), dst)\n\u001b[1;32m    253\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 254\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m fsrc:\n\u001b[1;32m    255\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    256\u001b[0m             \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(dst, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m fdst:\n\u001b[1;32m    257\u001b[0m                 \u001b[38;5;66;03m# macOS\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../../Maya_competition_lidar_data/images/train/tile_0_lidar.tif'"
     ]
    }
   ],
   "source": [
    "#import images form dataset\n",
    "\n",
    "\n",
    "IMAGE_INPUT_DIRECTORY = ''\n",
    "IMAGE_OUTPUT_DIRECTORY = './imgs'\n",
    "\n",
    "TILE_RANGE=100\n",
    "\n",
    "#! ls './imgs'\n",
    "#! ls '../../Maya_competition_lidar_data/images/train'\n",
    "\n",
    "# Copying the images\n",
    "for i in range(TILE_RANGE):\n",
    "    input_image_path = os.path.join(IMAGE_INPUT_DIRECTORY, f'tile_{i}_lidar.tif')\n",
    "    output_image_path = os.path.join(IMAGE_OUTPUT_DIRECTORY, f'tile_{i}.tif')\n",
    "    shutil.copy2(input_image_path,output_image_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "183dbb64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#copy train masks\n",
    "\n",
    "train_number = 100\n",
    "\n",
    "IMAGE_INPUT_DIRECTORY = '/Users/user/Library/Mobile Documents/com~apple~CloudDocs/[02]-work/[02]-2023-le-wagon/[04]-final-project/train_data/train_masks'\n",
    "IMAGE_OUTPUT_DIRECTORY_AGUADA = '/Users/user/Desktop/MAIA-yolo/0_first_run/dataset/train_mask/aguada/'\n",
    "IMAGE_OUTPUT_DIRECTORY_BUILDING = '/Users/user/Desktop/MAIA-yolo/0_first_run/dataset/train_mask/building/'\n",
    "IMAGE_OUTPUT_DIRECTORY_PLATFORM = '/Users/user/Desktop/MAIA-yolo/0_first_run/dataset/train_mask/platform/'\n",
    "\n",
    "for i in range(train_number):\n",
    "    input_image_path = os.path.join(IMAGE_INPUT_DIRECTORY, f'tile_{i}_mask_aguada.tif')\n",
    "    output_image_path = os.path.join(IMAGE_OUTPUT_DIRECTORY_AGUADA, f'tile_{i}.tif')\n",
    "    shutil.copy2(input_image_path,output_image_path)\n",
    "\n",
    "for i in range(train_number):\n",
    "    input_image_path = os.path.join(IMAGE_INPUT_DIRECTORY, f'tile_{i}_mask_building.tif')\n",
    "    output_image_path = os.path.join(IMAGE_OUTPUT_DIRECTORY_BUILDING, f'tile_{i}.tif')\n",
    "    shutil.copy2(input_image_path,output_image_path)\n",
    "    \n",
    "for i in range(train_number):\n",
    "    input_image_path = os.path.join(IMAGE_INPUT_DIRECTORY, f'tile_{i}_mask_platform.tif')\n",
    "    output_image_path = os.path.join(IMAGE_OUTPUT_DIRECTORY_PLATFORM, f'tile_{i}.tif')\n",
    "    shutil.copy2(input_image_path,output_image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c2259304",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To run the mask to COCO conversion: Use main_maia.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e419e0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To convert COCO to use: https://github.com/ultralytics/JSON2YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "caa4f37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import contextlib\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "from PIL import ExifTags\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6467e0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "img_formats = ['bmp', 'jpg', 'jpeg', 'png', 'tif', 'tiff', 'dng']  # acceptable image suffixes\n",
    "vid_formats = ['mov', 'avi', 'mp4', 'mpg', 'mpeg', 'm4v', 'wmv', 'mkv']  # acceptable video suffixes\n",
    "\n",
    "# Get orientation exif tag\n",
    "for orientation in ExifTags.TAGS.keys():\n",
    "    if ExifTags.TAGS[orientation] == 'Orientation':\n",
    "        break\n",
    "\n",
    "\n",
    "def exif_size(img):\n",
    "    # Returns exif-corrected PIL size\n",
    "    s = img.size  # (width, height)\n",
    "    try:\n",
    "        rotation = dict(img._getexif().items())[orientation]\n",
    "        if rotation in [6, 8]:  # rotation 270\n",
    "            s = (s[1], s[0])\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    return s\n",
    "\n",
    "\n",
    "def split_rows_simple(file='../data/sm4/out.txt'):  # from utils import *; split_rows_simple()\n",
    "    # splits one textfile into 3 smaller ones based upon train, test, val ratios\n",
    "    with open(file) as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    s = Path(file).suffix\n",
    "    lines = sorted(list(filter(lambda x: len(x) > 0, lines)))\n",
    "    i, j, k = split_indices(lines, train=0.9, test=0.1, validate=0.0)\n",
    "    for k, v in {'train': i, 'test': j, 'val': k}.items():  # key, value pairs\n",
    "        if v.any():\n",
    "            new_file = file.replace(s, f'_{k}{s}')\n",
    "            with open(new_file, 'w') as f:\n",
    "                f.writelines([lines[i] for i in v])\n",
    "\n",
    "\n",
    "def split_files(out_path, file_name, prefix_path=''):  # split training data\n",
    "    file_name = list(filter(lambda x: len(x) > 0, file_name))\n",
    "    file_name = sorted(file_name)\n",
    "    i, j, k = split_indices(file_name, train=0.9, test=0.1, validate=0.0)\n",
    "    datasets = {'train': i, 'test': j, 'val': k}\n",
    "    for key, item in datasets.items():\n",
    "        if item.any():\n",
    "            with open(f'{out_path}_{key}.txt', 'a') as file:\n",
    "                for i in item:\n",
    "                    file.write('%s%s\\n' % (prefix_path, file_name[i]))\n",
    "\n",
    "\n",
    "def split_indices(x, train=0.9, test=0.1, validate=0.0, shuffle=True):  # split training data\n",
    "    n = len(x)\n",
    "    v = np.arange(n)\n",
    "    if shuffle:\n",
    "        np.random.shuffle(v)\n",
    "\n",
    "    i = round(n * train)  # train\n",
    "    j = round(n * test) + i  # test\n",
    "    k = round(n * validate) + j  # validate\n",
    "    return v[:i], v[i:j], v[j:k]  # return indices\n",
    "\n",
    "\n",
    "def make_dirs(dir='new_dir/'):\n",
    "    # Create folders\n",
    "    dir = Path(dir)\n",
    "    if dir.exists():\n",
    "        shutil.rmtree(dir)  # delete dir\n",
    "    for p in dir, dir / 'labels', dir / 'images':\n",
    "        p.mkdir(parents=True, exist_ok=True)  # make dir\n",
    "    return dir\n",
    "\n",
    "\n",
    "def write_data_data(fname='data.data', nc=80):\n",
    "    # write darknet *.data file\n",
    "    lines = ['classes = %g\\n' % nc,\n",
    "             'train =../out/data_train.txt\\n',\n",
    "             'valid =../out/data_test.txt\\n',\n",
    "             'names =../out/data.names\\n',\n",
    "             'backup = backup/\\n',\n",
    "             'eval = coco\\n']\n",
    "\n",
    "    with open(fname, 'a') as f:\n",
    "        f.writelines(lines)\n",
    "\n",
    "\n",
    "def image_folder2file(folder='images/'):  # from utils import *; image_folder2file()\n",
    "    # write a txt file listing all imaged in folder\n",
    "    s = glob.glob(f'{folder}*.*')\n",
    "    with open(f'{folder[:-1]}.txt', 'w') as file:\n",
    "        for l in s:\n",
    "            file.write(l + '\\n')  # write image list\n",
    "\n",
    "\n",
    "def add_coco_background(path='../data/sm4/', n=1000):  # from utils import *; add_coco_background()\n",
    "    # add coco background to sm4 in outb.txt\n",
    "    p = f'{path}background'\n",
    "    if os.path.exists(p):\n",
    "        shutil.rmtree(p)  # delete output folder\n",
    "    os.makedirs(p)  # make new output folder\n",
    "\n",
    "    # copy images\n",
    "    for image in glob.glob('../coco/images/train2014/*.*')[:n]:\n",
    "        os.system(f'cp {image} {p}')\n",
    "\n",
    "    # add to outb.txt and make train, test.txt files\n",
    "    f = f'{path}out.txt'\n",
    "    fb = f'{path}outb.txt'\n",
    "    os.system(f'cp {f} {fb}')\n",
    "    with open(fb, 'a') as file:\n",
    "        file.writelines(i + '\\n' for i in glob.glob(f'{p}/*.*'))\n",
    "    split_rows_simple(file=fb)\n",
    "\n",
    "\n",
    "def create_single_class_dataset(path='../data/sm3'):  # from utils import *; create_single_class_dataset('../data/sm3/')\n",
    "    # creates a single-class version of an existing dataset\n",
    "    os.system(f'mkdir {path}_1cls')\n",
    "\n",
    "\n",
    "def flatten_recursive_folders(path='../../Downloads/data/sm4/'):  # from utils import *; flatten_recursive_folders()\n",
    "    # flattens nested folders in path/images and path/JSON into single folders\n",
    "    idir, jdir = f'{path}images/', f'{path}json/'\n",
    "    nidir, njdir = Path(f'{path}images_flat/'), Path(f'{path}json_flat/')\n",
    "    n = 0\n",
    "\n",
    "    # Create output folders\n",
    "    for p in [nidir, njdir]:\n",
    "        if os.path.exists(p):\n",
    "            shutil.rmtree(p)  # delete output folder\n",
    "        os.makedirs(p)  # make new output folder\n",
    "\n",
    "    for parent, dirs, files in os.walk(idir):\n",
    "        for f in tqdm(files, desc=parent):\n",
    "            f = Path(f)\n",
    "            stem, suffix = f.stem, f.suffix\n",
    "            if suffix.lower()[1:] in img_formats:\n",
    "                n += 1\n",
    "                stem_new = '%g_' % n + stem\n",
    "                image_new = nidir / (stem_new + suffix)  # converts all formats to *.jpg\n",
    "                json_new = njdir / f'{stem_new}.json'\n",
    "\n",
    "                image = parent / f\n",
    "                json = Path(parent.replace('images', 'json')) / str(f).replace(suffix, '.json')\n",
    "\n",
    "                os.system(\"cp '%s' '%s'\" % (json, json_new))\n",
    "                os.system(\"cp '%s' '%s'\" % (image, image_new))\n",
    "                # cv2.imwrite(str(image_new), cv2.imread(str(image)))\n",
    "\n",
    "    print('Flattening complete: %g jsons and images' % n)\n",
    "\n",
    "\n",
    "def coco91_to_coco80_class():  # converts 80-index (val2014) to 91-index (paper)\n",
    "    # https://tech.amikelive.com/node-718/what-object-categories-labels-are-in-coco-dataset/\n",
    "    x = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, None, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, None, 24, 25, None,\n",
    "         None, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, None, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n",
    "         51, 52, 53, 54, 55, 56, 57, 58, 59, None, 60, None, None, 61, None, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72,\n",
    "         None, 73, 74, 75, 76, 77, 78, 79, None]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "60e72ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_coco_json(json_dir='../output/', use_segments=True, cls91to80=False):\n",
    "    save_dir = make_dirs()  # output directory\n",
    "    coco80 = coco91_to_coco80_class()\n",
    "\n",
    "    # Import json\n",
    "    for json_file in sorted(Path(json_dir).resolve().glob('*.json')):\n",
    "        fn = Path(save_dir) / 'labels' / json_file.stem.replace('instances_', '')  # folder name\n",
    "        fn.mkdir()\n",
    "        with open(json_file) as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        # Create image dict\n",
    "        images = {'%g' % x['id']: x for x in data['images']}\n",
    "        # Create image-annotations dict\n",
    "        imgToAnns = defaultdict(list)\n",
    "        for ann in data['annotations']:\n",
    "            imgToAnns[ann['image_id']].append(ann)\n",
    "\n",
    "        # Write labels file\n",
    "        for img_id, anns in tqdm(imgToAnns.items(), desc=f'Annotations {json_file}'):\n",
    "            img = images['%g' % img_id]\n",
    "            h, w, f = img['height'], img['width'], img['file_name']\n",
    "\n",
    "            bboxes = []\n",
    "            segments = []\n",
    "            for ann in anns:\n",
    "                if ann['iscrowd']:\n",
    "                    continue\n",
    "                # The COCO box format is [top left x, top left y, width, height]\n",
    "                box = np.array(ann['bbox'], dtype=np.float64)\n",
    "                box[:2] += box[2:] / 2  # xy top-left corner to center\n",
    "                box[[0, 2]] /= w  # normalize x\n",
    "                box[[1, 3]] /= h  # normalize y\n",
    "                if box[2] <= 0 or box[3] <= 0:  # if w <= 0 and h <= 0\n",
    "                    continue\n",
    "\n",
    "                cls = coco80[ann['category_id'] - 1] if cls91to80 else ann['category_id'] - 1  # class\n",
    "                box = [cls] + box.tolist()\n",
    "                if box not in bboxes:\n",
    "                    bboxes.append(box)\n",
    "                # Segments\n",
    "                if use_segments:\n",
    "                    if len(ann['segmentation']) > 1:\n",
    "                        s = merge_multi_segment(ann['segmentation'])\n",
    "                        s = (np.concatenate(s, axis=0) / np.array([w, h])).reshape(-1).tolist()\n",
    "                    else:\n",
    "                        s = [j for i in ann['segmentation'] for j in i]  # all segments concatenated\n",
    "                        s = (np.array(s).reshape(-1, 2) / np.array([w, h])).reshape(-1).tolist()\n",
    "                    s = [cls] + s\n",
    "                    if s not in segments:\n",
    "                        segments.append(s)\n",
    "\n",
    "            # Write\n",
    "            with open((fn / f).with_suffix('.txt'), 'a') as file:\n",
    "                for i in range(len(bboxes)):\n",
    "                    line = *(segments[i] if use_segments else bboxes[i]),  # cls, box or segments\n",
    "                    file.write(('%g ' * len(line)).rstrip() % line + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "a9f26636",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Annotations /Users/user/Desktop/MAIA-yolo/0_first_run/output/train.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 76/76 [00:00<00:00, 1113.78it/s]\n"
     ]
    }
   ],
   "source": [
    "# Output is under: /new_dir/labels\n",
    "# Chould then be checked in Roboflow - but need to convert the images to JPEG or PNG\n",
    "convert_coco_json(json_dir='../output', use_segments=True, cls91to80=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d468effd",
   "metadata": {},
   "source": [
    "# 2. Convert from tif to jpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "673ba9df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'imgs/tile_0.tif'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [137], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m100\u001b[39m):\n\u001b[0;32m----> 5\u001b[0m     im \u001b[38;5;241m=\u001b[39m \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimgs/tile_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mi\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.tif\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     im\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnew_dir/images/tile_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.jpeg\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/PIL/Image.py:3068\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3065\u001b[0m     filename \u001b[38;5;241m=\u001b[39m fp\n\u001b[1;32m   3067\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filename:\n\u001b[0;32m-> 3068\u001b[0m     fp \u001b[38;5;241m=\u001b[39m \u001b[43mbuiltins\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3069\u001b[0m     exclusive_fp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   3071\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'imgs/tile_0.tif'"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "\n",
    "for i in range(100):\n",
    "    im = Image.open(f'imgs/tile_{i}.tif')\n",
    "    im.save(f'new_dir/images/tile_{i}.jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0225c664",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Copy and transform images for training\n",
    "IMAGE_INPUT_DIRECTORY = '/Users/user/Library/Mobile Documents/com~apple~CloudDocs/[02]-work/[02]-2023-le-wagon/[04]-final-project/train_data/train_lidar/'\n",
    "IMAGE_OUTPUT_DIRECTORY = './imgs'\n",
    "\n",
    "TILE_RANGE=100\n",
    "\n",
    "#! ls './imgs'\n",
    "#! ls '../../Maya_competition_lidar_data/images/train'\n",
    "\n",
    "# Copying the images\n",
    "for i in range(TILE_RANGE):\n",
    "    input_image_path = os.path.join(IMAGE_INPUT_DIRECTORY, f'tile_{i}.tif')\n",
    "    output_image_path = os.path.join(IMAGE_OUTPUT_DIRECTORY, f'tile_{i}.tif')\n",
    "    shutil.copy2(input_image_path,output_image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086c9f5e",
   "metadata": {},
   "source": [
    "# 3. YOLO v8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "373fec40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ultralytics in /Users/user/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (8.0.0)\n",
      "Requirement already satisfied: hydra-core>=1.2.0 in /Users/user/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from ultralytics) (1.3.2)\n",
      "Requirement already satisfied: matplotlib>=3.2.2 in /Users/user/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from ultralytics) (3.5.3)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /Users/user/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from ultralytics) (1.23.4)\n",
      "Requirement already satisfied: opencv-python>=4.1.1 in /Users/user/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from ultralytics) (4.8.0.74)\n",
      "Requirement already satisfied: Pillow>=7.1.2 in /Users/user/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from ultralytics) (9.1.1)\n",
      "Requirement already satisfied: PyYAML>=5.3.1 in /Users/user/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from ultralytics) (5.4.1)\n",
      "Requirement already satisfied: requests>=2.23.0 in /Users/user/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from ultralytics) (2.28.1)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /Users/user/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from ultralytics) (1.8.1)\n",
      "Requirement already satisfied: torch>=1.7.0 in /Users/user/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from ultralytics) (2.0.1)\n",
      "Requirement already satisfied: torchvision>=0.8.1 in /Users/user/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from ultralytics) (0.15.2)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in /Users/user/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from ultralytics) (4.64.1)\n",
      "Requirement already satisfied: tensorboard>=2.4.1 in /Users/user/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from ultralytics) (2.10.1)\n",
      "Requirement already satisfied: pandas>=1.1.4 in /Users/user/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from ultralytics) (1.4.4)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in /Users/user/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from ultralytics) (0.11.2)\n",
      "Requirement already satisfied: ipython in /Users/user/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from ultralytics) (8.5.0)\n",
      "Requirement already satisfied: psutil in /Users/user/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from ultralytics) (5.9.3)\n",
      "Requirement already satisfied: thop>=0.1.1 in /Users/user/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from ultralytics) (0.1.1.post2209072238)\n",
      "Requirement already satisfied: GitPython>=3.1.24 in /Users/user/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from ultralytics) (3.1.29)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /Users/user/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from GitPython>=3.1.24->ultralytics) (4.0.9)\n",
      "Requirement already satisfied: omegaconf<2.4,>=2.2 in /Users/user/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from hydra-core>=1.2.0->ultralytics) (2.3.0)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /Users/user/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from hydra-core>=1.2.0->ultralytics) (4.9.3)\n",
      "Requirement already satisfied: packaging in /Users/user/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from hydra-core>=1.2.0->ultralytics) (21.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/user/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from matplotlib>=3.2.2->ultralytics) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/user/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from matplotlib>=3.2.2->ultralytics) (4.38.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/user/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from matplotlib>=3.2.2->ultralytics) (1.4.4)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /Users/user/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from matplotlib>=3.2.2->ultralytics) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/user/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from matplotlib>=3.2.2->ultralytics) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/user/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from pandas>=1.1.4->ultralytics) (2022.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/user/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/user/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/user/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (1.26.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/user/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (2022.9.24)\n",
      "Requirement already satisfied: absl-py>=0.4 in /Users/user/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from tensorboard>=2.4.1->ultralytics) (1.3.0)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /Users/user/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from tensorboard>=2.4.1->ultralytics) (1.50.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /Users/user/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from tensorboard>=2.4.1->ultralytics) (2.13.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /Users/user/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from tensorboard>=2.4.1->ultralytics) (0.4.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/user/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from tensorboard>=2.4.1->ultralytics) (3.4.1)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /Users/user/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from tensorboard>=2.4.1->ultralytics) (3.19.6)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /Users/user/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from tensorboard>=2.4.1->ultralytics) (63.2.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /Users/user/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from tensorboard>=2.4.1->ultralytics) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /Users/user/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from tensorboard>=2.4.1->ultralytics) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/user/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from tensorboard>=2.4.1->ultralytics) (2.2.2)\n",
      "Requirement already satisfied: wheel>=0.26 in /Users/user/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from tensorboard>=2.4.1->ultralytics) (0.38.4)\n",
      "Requirement already satisfied: filelock in /Users/user/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from torch>=1.7.0->ultralytics) (3.12.2)\n",
      "Requirement already satisfied: typing-extensions in /Users/user/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from torch>=1.7.0->ultralytics) (4.4.0)\n",
      "Requirement already satisfied: sympy in /Users/user/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from torch>=1.7.0->ultralytics) (1.12)\n",
      "Requirement already satisfied: networkx in /Users/user/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from torch>=1.7.0->ultralytics) (2.8.7)\n",
      "Requirement already satisfied: jinja2 in /Users/user/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from torch>=1.7.0->ultralytics) (3.1.2)\n",
      "Requirement already satisfied: backcall in /Users/user/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from ipython->ultralytics) (0.2.0)\n",
      "Requirement already satisfied: decorator in /Users/user/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from ipython->ultralytics) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /Users/user/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from ipython->ultralytics) (0.18.1)\n",
      "Requirement already satisfied: matplotlib-inline in /Users/user/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from ipython->ultralytics) (0.1.6)\n",
      "Requirement already satisfied: pickleshare in /Users/user/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from ipython->ultralytics) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>3.0.1 in /Users/user/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from ipython->ultralytics) (3.0.31)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /Users/user/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from ipython->ultralytics) (2.13.0)\n",
      "Requirement already satisfied: stack-data in /Users/user/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from ipython->ultralytics) (0.5.1)\n",
      "Requirement already satisfied: traitlets>=5 in /Users/user/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from ipython->ultralytics) (5.5.0)\n",
      "Requirement already satisfied: pexpect>4.3 in /Users/user/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from ipython->ultralytics) (4.8.0)\n",
      "Requirement already satisfied: appnope in /Users/user/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from ipython->ultralytics) (0.1.3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: smmap<6,>=3.0.1 in /Users/user/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->GitPython>=3.1.24->ultralytics) (5.0.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/user/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->ultralytics) (5.2.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/user/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->ultralytics) (0.2.8)\n",
      "Requirement already satisfied: six>=1.9.0 in /Users/user/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->ultralytics) (1.16.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/user/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->ultralytics) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/user/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.1->ultralytics) (1.3.1)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /Users/user/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from jedi>=0.16->ipython->ultralytics) (0.8.3)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /Users/user/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from pexpect>4.3->ipython->ultralytics) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /Users/user/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from prompt-toolkit<3.1.0,>3.0.1->ipython->ultralytics) (0.2.5)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/user/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard>=2.4.1->ultralytics) (2.1.1)\n",
      "Requirement already satisfied: executing in /Users/user/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from stack-data->ipython->ultralytics) (1.1.1)\n",
      "Requirement already satisfied: asttokens in /Users/user/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from stack-data->ipython->ultralytics) (2.0.8)\n",
      "Requirement already satisfied: pure-eval in /Users/user/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from stack-data->ipython->ultralytics) (0.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/user/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from sympy->torch>=1.7.0->ultralytics) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /Users/user/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.4.1->ultralytics) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/user/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.1->ultralytics) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "bdd1d7fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pycocotools\n",
      "  Downloading pycocotools-2.0.6.tar.gz (24 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: matplotlib>=2.1.0 in /Users/user/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from pycocotools) (3.5.3)\n",
      "Requirement already satisfied: numpy in /Users/user/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from pycocotools) (1.23.4)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/user/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/user/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools) (4.38.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/user/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/user/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools) (21.3)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/user/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools) (9.1.1)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /Users/user/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/user/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/user/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib>=2.1.0->pycocotools) (1.16.0)\n",
      "Building wheels for collected packages: pycocotools\n",
      "  Building wheel for pycocotools (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pycocotools: filename=pycocotools-2.0.6-cp310-cp310-macosx_13_0_x86_64.whl size=90617 sha256=93d9f434f9c059286b994a85480cb2393beafe763e08ab10d47cea06cfdb463d\n",
      "  Stored in directory: /Users/user/Library/Caches/pip/wheels/58/e6/f9/f87c8f8be098b51b616871315318329cae12cdb618f4caac93\n",
      "Successfully built pycocotools\n",
      "Installing collected packages: pycocotools\n",
      "Successfully installed pycocotools-2.0.6\n"
     ]
    }
   ],
   "source": [
    "! pip install pycocotools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "5ed1949c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1myolo/engine/trainer: \u001b[0mtask=segment, mode=train, model=yolov8s-seg.yaml, data=custom.yaml, epochs=3, patience=50, batch=16, imgsz=640, save=True, cache=False, device=None, workers=8, project=None, name=None, exist_ok=False, pretrained=False, optimizer=SGD, verbose=False, seed=0, deterministic=True, single_cls=False, image_weights=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, overlap_mask=True, mask_ratio=4, dropout=False, val=True, save_json=False, save_hybrid=False, conf=0.001, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=ultralytics/assets/, show=False, save_txt=False, save_conf=False, save_crop=False, hide_labels=False, hide_conf=False, vid_stride=1, line_thickness=3, visualize=False, augment=False, agnostic_nms=False, retina_masks=False, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=17, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.001, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, fl_gamma=0.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.6, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, hydra={'output_subdir': None, 'run': {'dir': '.'}}, v5loader=False, save_dir=runs/segment/train12\n",
      "Ultralytics YOLOv8.0.0 ðŸš€ Python-3.10.6 torch-2.0.1 CPU\n",
      "Overriding model.yaml nc=80 with nc=3\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.Conv                  [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.Conv                  [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.C2f                   [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.Conv                  [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.C2f                   [128, 128, 2, True]           \n",
      "  5                  -1  1    295424  ultralytics.nn.modules.Conv                  [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.C2f                   [256, 256, 2, True]           \n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.Conv                  [256, 512, 3, 2]              \n",
      "  8                  -1  1   1838080  ultralytics.nn.modules.C2f                   [512, 512, 1, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.SPPF                  [512, 512, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 12                  -1  1    591360  ultralytics.nn.modules.C2f                   [768, 256, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 15                  -1  1    148224  ultralytics.nn.modules.C2f                   [384, 128, 1]                 \n",
      " 16                  -1  1    147712  ultralytics.nn.modules.Conv                  [128, 128, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 18                  -1  1    493056  ultralytics.nn.modules.C2f                   [384, 256, 1]                 \n",
      " 19                  -1  1    590336  ultralytics.nn.modules.Conv                  [256, 256, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 21                  -1  1   1969152  ultralytics.nn.modules.C2f                   [768, 512, 1]                 \n",
      " 22        [15, 18, 21]  1   2771705  ultralytics.nn.modules.Segment               [3, 32, 128, [128, 256, 512]] \n",
      "YOLOv8s-seg summary: 261 layers, 11791257 parameters, 11791241 gradients, 42.7 GFLOPs\n",
      "\n",
      "Transferred 411/417 items from pretrained weights\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 66 weight(decay=0.0), 77 weight(decay=0.001), 76 bias\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/user/Desktop/MAIA-yolo/0_first_run/datasets/images-v1/labels/train.cache... 9 images, 6 backgrounds,\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/user/Desktop/MAIA-yolo/0_first_run/datasets/images-v1/labels/val.cache... 4 images, 1 backgrounds, 0 c\u001b[0m\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train12\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/3         0G      1.589      4.078      4.453      1.494         65        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  \n",
      "                   all          5         22      0.227        0.1     0.0659      0.044      0.227        0.1     0.0583     0.0258\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/3         0G      1.603      4.683       3.96      1.372        133        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  \n",
      "                   all          5         22      0.225        0.1     0.0665     0.0443      0.225        0.1     0.0576     0.0253\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/3         0G      1.707      3.973      3.868      1.426        145        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  \n",
      "                   all          5         22      0.225        0.1      0.067     0.0454      0.225        0.1      0.058     0.0255\n",
      "\n",
      "3 epochs completed in 0.015 hours.\n",
      "Optimizer stripped from runs/segment/train12/weights/last.pt, 23.9MB\n",
      "Optimizer stripped from runs/segment/train12/weights/best.pt, 23.9MB\n",
      "\n",
      "Validating runs/segment/train12/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.0 ðŸš€ Python-3.10.6 torch-2.0.1 CPU\n",
      "Fusing layers... \n",
      "YOLOv8s-seg summary: 195 layers, 11780761 parameters, 0 gradients, 42.4 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  \n",
      "                   all          5         22      0.223        0.1     0.0679      0.046      0.223        0.1     0.0581     0.0349\n",
      "              building          5         17          0          0     0.0168     0.0109          0          0     0.0168     0.0109\n",
      "              platform          5          5      0.447        0.2      0.119     0.0811      0.447        0.2     0.0993      0.059\n",
      "Speed: 3.2ms pre-process, 245.5ms inference, 0.0ms loss, 14.8ms post-process per image\n",
      "Saving runs/segment/train12/predictions.json...\n",
      "Results saved to \u001b[1mruns/segment/train12\u001b[0m\n",
      "Ultralytics YOLOv8.0.0 ðŸš€ Python-3.10.6 torch-2.0.1 CPU\n",
      "Fusing layers... \n",
      "YOLOv8s-seg summary: 195 layers, 11780761 parameters, 82473 gradients, 42.4 GFLOPs\n",
      "\n",
      "Dataset not found âš ï¸, missing paths ['/Users/user/Desktop/MAIA-yolo/0_first_run/datasets/coco/val2017.txt']\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [146], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m results \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mtrain(data\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcustom.yaml\u001b[39m\u001b[38;5;124m'\u001b[39m, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Evaluate the model's performance on the validation set\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mval\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/ultralytics/yolo/engine/model.py:150\u001b[0m, in \u001b[0;36mYOLO.val\u001b[0;34m(self, data, **kwargs)\u001b[0m\n\u001b[1;32m    147\u001b[0m args\u001b[38;5;241m.\u001b[39mtask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtask\n\u001b[1;32m    149\u001b[0m validator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mValidatorClass(args\u001b[38;5;241m=\u001b[39margs)\n\u001b[0;32m--> 150\u001b[0m \u001b[43mvalidator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/ultralytics/yolo/engine/validator.py:112\u001b[0m, in \u001b[0;36mBaseValidator.__call__\u001b[0;34m(self, trainer, model)\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39minfo(\n\u001b[1;32m    109\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mForcing --batch-size 1 square inference (1,3,\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimgsz\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimgsz\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) for non-PyTorch models\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdata, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.yaml\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 112\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_dataset_yaml\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m check_dataset(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdata)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/ultralytics/yolo/data/utils.py:251\u001b[0m, in \u001b[0;36mcheck_dataset_yaml\u001b[0;34m(data, autodownload)\u001b[0m\n\u001b[1;32m    249\u001b[0m     r \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39msystem(s)\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# python script\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[43mexec\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43myaml\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# return None\u001b[39;00m\n\u001b[1;32m    252\u001b[0m dt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mround\u001b[39m(time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m t, \u001b[38;5;241m1\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124ms)\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    253\u001b[0m s \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msuccess âœ… \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdt\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, saved to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcolorstr(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbold\u001b[39m\u001b[38;5;124m'\u001b[39m, DATASETS_DIR)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfailure \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdt\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m âŒ\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m<string>:1\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'utils'"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Create a new YOLO model from scratch\n",
    "#model = YOLO('yolov8n.yaml')\n",
    "\n",
    "# Load a pretrained YOLO model (recommended for training)\n",
    "model = YOLO('yolov8s-seg.pt')\n",
    "\n",
    "# Train the model using the 'coco128.yaml' dataset for 3 epochs\n",
    "results = model.train(data='custom.yaml', epochs=3)\n",
    "\n",
    "# Evaluate the model's performance on the validation set\n",
    "results = model.val()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8e9f187c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.0 ðŸš€ Python-3.10.6 torch-2.0.1 CPU\n",
      "Fusing layers... \n",
      "YOLOv8n-seg summary: 195 layers, 3258649 parameters, 32681 gradients, 12.0 GFLOPs\n",
      "image 1/1 /Users/user/Desktop/MAIA-yolo/0_first_run/datasets/images-v0/tile_1780_lidar.jpeg: 640x640 104.2ms\n",
      "Speed: 1.5ms pre-process, 104.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    }
   ],
   "source": [
    "# Perform object detection on an image using the model\n",
    "results = model('/Users/user/Desktop/MAIA-yolo/0_first_run/datasets/images-v0/tile_1780_lidar.jpeg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22d0dca",
   "metadata": {},
   "source": [
    "# Contours with OpenCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf88b89",
   "metadata": {},
   "source": [
    "We will be making a copy of our original image using img.copy() to draw contours on that copy image so that our original image is preserved.\n",
    "To draw contours we use cv2.drawContours() method. The first argument represents the image source, the second argument represents the contours that should be passed as a Python list, the third argument is used as an index of Contours, and other arguments are used for color thickness.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "a13c0d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def contours_detection(tile):\n",
    "    path = '/Users/user/Library/Mobile Documents/com~apple~CloudDocs/[02]-work/[02]-2023-le-wagon/[04]-final-project/train_data/\\\n",
    "train_masks/' + f'{tile}' + '.tif'\n",
    "    #read image\n",
    "    img = cv2.imread(path) \n",
    "    #convert from BGR to RGB\n",
    "    img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB) \n",
    "    #convert to greyscale for thersholding\n",
    "    gray = cv2.cvtColor(img.copy(),cv2.COLOR_BGR2GRAY)\n",
    "    gray=255-gray\n",
    "    #Thresholding the image to detect contours\n",
    "    ret, thresh = cv2.threshold(gray, 125, 255, 0)\n",
    "    #(Image.fromarray(thresh)).show()\n",
    "    #Letâ€™s detect contoursâ€¦\n",
    "    #Syntax: cv2.findContours(src, contour_retrieval, contours_approximation)\n",
    "    contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    print(len(contours))\n",
    "    copy_img = img.copy()\n",
    "    cv2.drawContours(copy_img,contours,-1,(255,0,0),2)\n",
    "    titles = ['original','contours']\n",
    "    imgs = [img, copy_img]\n",
    "    for i in range (2):\n",
    "        plt.subplot(1,2,i+1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.title(titles[i])\n",
    "        plt.imshow(imgs[i])\n",
    "    \n",
    "    return plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a16f613",
   "metadata": {},
   "outputs": [],
   "source": [
    "contours_detection('tile_4_mask_building')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "97576cec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "contours_detection('tile_0_mask_building')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "c3873c9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "contours_detection('tile_1257_mask_platform')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "fdac84f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255]],\n",
       "\n",
       "       [[  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255]],\n",
       "\n",
       "       [[  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255]],\n",
       "\n",
       "       [[255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255]],\n",
       "\n",
       "       [[255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255]]], dtype=uint8)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = '/Users/user/Library/Mobile Documents/com~apple~CloudDocs/[02]-work/[02]-2023-le-wagon/[04]-final-project/train_data/\\\n",
    "train_masks/tile_1257_mask_platform.tif'\n",
    "img = cv2.imread(path)\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522a6e27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b8f758",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
